{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPH8g6pNirn0Vc6IVf9hoos",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sebastian352/Endoscope-Semantic-Segmentation-using-Unet/blob/master/unet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/Project')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3FIiEQ8x_Ku",
        "outputId": "ca854e42-8148-407e-9d81-0549c5320b0e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/Project/MyDrive/Project/video_archive.zip -d /content/sample_data/video_content"
      ],
      "metadata": {
        "id": "L4bZ2zP_x_-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "M4vKyjoN3YGH"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import shutil\n",
        "from google.colab.patches import cv2_imshow\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau,CSVLogger\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(input, num_filters):\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "s5xl_fo44QJa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder_block(input, num_filters):\n",
        "    x = conv_block(input, num_filters)\n",
        "    p = MaxPool2D((2, 2))(x)\n",
        "    return x, p"
      ],
      "metadata": {
        "id": "lapYYyULR_vG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decoder_block(input, skip_features, num_filters):\n",
        "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
        "    x = Concatenate()([x, skip_features])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x"
      ],
      "metadata": {
        "id": "h5VHtGrj9CQR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_unet(input_shape, num_classes):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    s1, p1 = encoder_block(inputs, 64)\n",
        "    s2, p2 = encoder_block(p1, 128)\n",
        "    s3, p3 = encoder_block(p2, 256)\n",
        "    s4, p4 = encoder_block(p3, 512)\n",
        "\n",
        "    b1 = conv_block(p4, 1024)\n",
        "\n",
        "    d1 = decoder_block(b1, s4, 512)\n",
        "    d2 = decoder_block(d1, s3, 256)\n",
        "    d3 = decoder_block(d2, s2, 128)\n",
        "    d4 = decoder_block(d3, s1, 64)\n",
        "\n",
        "    outputs = Conv2D(num_classes, 1, padding=\"same\", activation=\"softmax\")(d4)\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"U-Net\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "t6NADJ0g_4-O"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dir(path):\n",
        "  if not os.path.exists(path):\n",
        "    os.makedirs(path)"
      ],
      "metadata": {
        "id": "bJC-C4mOR5Tq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def move_data(path,rawImagesPath,maskImagesPath):\n",
        "  for directory in os.listdir(path):\n",
        "    dirPath = os.path.join(path, directory)\n",
        "    for subDir in os.listdir(dirPath):\n",
        "      subSubDir = os.path.join(dirPath, subDir)\n",
        "      for image in os.listdir(subSubDir):\n",
        "        srcPath = os.path.join(subSubDir, image)\n",
        "        newName = subDir + image\n",
        "        if 'mask' not in image:\n",
        "          newPath = os.path.join(rawImagesPath, newName)\n",
        "          destPath = os.path.join(rawImagesPath, image)\n",
        "          shutil.copy(srcPath, destPath)\n",
        "          os.rename(destPath, newPath)\n",
        "        if 'color' in image:\n",
        "          newPath = os.path.join(maskImagesPath, newName)\n",
        "          destPath = os.path.join(maskImagesPath, image)\n",
        "          shutil.copy(srcPath, destPath)\n",
        "          os.rename(destPath, newPath)"
      ],
      "metadata": {
        "id": "f1dvvBuMyaRI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_path(images):\n",
        "  for i in range(len(images)):\n",
        "    if 'mask' not in images[i]:\n",
        "      images[i] = os.path.join(rawImagesPath,images[i])\n",
        "    else:\n",
        "      images[i] = os.path.join(maskImagesPath,images[i])\n",
        "    return images"
      ],
      "metadata": {
        "id": "Lcy9q-vTNBN1"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_image(image_path):\n",
        "  img = cv2.imread(image_path,cv2.IMREAD_COLOR)\n",
        "  img = cv2.resize(img,(IMG_W,IMG_H))\n",
        "  img = img/255.0\n",
        "  img = img.astype(np.float32)\n",
        "  return img\n",
        "\n",
        "def read_mask(mask_path):\n",
        "  img = cv2.imread(mask_path,cv2.IMREAD_COLOR)\n",
        "  img = cv2.resize(img,(IMG_W,IMG_H))\n",
        "  cv2_imshow(img)\n",
        "  output = []\n",
        "  for color,_ in color_class_mapping.items():\n",
        "    cmap = np.all(np.equal(img,color),axis=-1)\n",
        "    output.append(cmap)\n",
        "  output = np.stack(output,axis=-1)\n",
        "  output = output.astype(np.uint8)\n",
        "\n",
        "  return output"
      ],
      "metadata": {
        "id": "ZWFjpacl5dxB"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(image_path,mask_path):\n",
        "  def read(image_path,mask_path):\n",
        "    image_path = image_path.decode()\n",
        "    mask_path = mask_path.decode()\n",
        "\n",
        "    x = read_image(image_path)\n",
        "    y = read_mask(mask_path)\n",
        "    return x,y\n",
        "\n",
        "  image,mask = tf.numpy_function(read,[image_path,mask_path],[tf.float32,tf.uint8])\n",
        "  image.set_shape([IMG_H,IMG_W,3])\n",
        "  mask.set_shape([IMG_H,IMG_W,NUM_CLASSES])\n",
        "\n",
        "  return image,mask"
      ],
      "metadata": {
        "id": "BPMJ4-9x9zpv"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tf_dataset(image_path,mask_path,batch=8):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((image_path,mask_path))\n",
        "  dataset = dataset.shuffle(buffer_size = 5000)\n",
        "  dataset = dataset.map(preprocess)\n",
        "  dataset = dataset.prefetch(2)\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "TlVWxZX__1vn"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "Zk3fv01_wYsK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Hyperparameters \"\"\"\n",
        "IMG_H = 320\n",
        "IMG_W = 416\n",
        "NUM_CLASSES = 12\n",
        "input_shape = (IMG_H,IMG_W, 3)\n",
        "batch_size = 32\n",
        "lr = 1e-4\n",
        "epochs = 100\n",
        "\n",
        "path = '/content/sample_data/video_content'\n",
        "opPath = '/content'\n",
        "\n",
        "model_path = os.path.join(opPath,\"model.h5\")\n",
        "csv_path = os.path.join(opPath,\"data.csv\")\n",
        "\n",
        "\n",
        "rawImagesPath = os.path.join(opPath, 'rawImages')\n",
        "maskImagesPath = os.path.join(opPath, 'maskImages')\n",
        "labelsPath = os.path.join(opPath, 'labels')\n",
        "\n",
        "imgTrainPath = os.path.join(opPath,'images','train')\n",
        "imgCrossPath=os.path.join(opPath,'images','cross')\n",
        "imgTestPath=os.path.join(opPath,'images','test')\n",
        "\n",
        "labelTrainPath=os.path.join(opPath,'labels','train')\n",
        "labelCrossPath=os.path.join(opPath,'labels','cross')\n",
        "labelTestPath=os.path.join(opPath,'labels','test')\n"
      ],
      "metadata": {
        "id": "FvH6SZXgwfay"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Loading the dataset \"\"\"\n",
        "\n",
        "create_dir(rawImagesPath)\n",
        "create_dir(maskImagesPath)\n",
        "# create_dir(labelsPath)\n",
        "\n",
        "# create_dir(imgTrainPath)\n",
        "# create_dir(imgCrossPath)\n",
        "# create_dir(imgTestPath)\n",
        "\n",
        "# create_dir(labelTrainPath)\n",
        "# create_dir(labelCrossPath)\n",
        "# create_dir(labelTestPath)\n",
        "\n",
        "move_data(path,rawImagesPath,maskImagesPath)"
      ],
      "metadata": {
        "id": "VyqOYXWcxeWX"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rawImages = sorted(os.listdir(rawImagesPath))\n",
        "maskImages = sorted(os.listdir(maskImagesPath))\n",
        "add_path(rawImages)\n",
        "add_path(maskImages)"
      ],
      "metadata": {
        "id": "E1ZcEWX8M24d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Splitting data \"\"\"\n",
        "train_x, temp_x, train_y,temp_y = train_test_split(rawImages,maskImages,test_size=0.3,random_state=42)\n",
        "val_x,test_x ,val_y, test_y = train_test_split(temp_x,temp_y,test_size=0.5,random_state=42)\n"
      ],
      "metadata": {
        "id": "hDWIyUFSLpXL"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Process the color map \"\"\"\n",
        "color_class_mapping={(127, 127, 127): 0,\n",
        "                    (140, 140, 210): 1,\n",
        "                    (114, 114, 255): 2,\n",
        "                    (156, 70, 231): 3,\n",
        "                    (75, 183, 186): 4,\n",
        "                    (0, 255, 170): 5,\n",
        "                    (0, 85, 255): 6,\n",
        "                    (0, 0, 255): 7,\n",
        "                    (0, 255, 255): 8,\n",
        "                    (184, 255, 169): 9,\n",
        "                    (165, 160, 255): 10,\n",
        "                    (128, 50, 0): 11,\n",
        "                    (0, 74, 111): 12}\n",
        "\n",
        "classNameMapping = {\n",
        "    0: 'Black Background',\n",
        "    1: 'Abdominal Wall',\n",
        "    2: 'Liver',\n",
        "    3: 'Gastrointestinal Tract',\n",
        "    4: 'Fat',\n",
        "    5: 'Grasper',\n",
        "    6: 'Connective Tissue',\n",
        "    7: 'Blood',\n",
        "    8: 'Cystic Duct',\n",
        "    9: 'L-hook Electrocautery',\n",
        "    10: 'Gallbladder',\n",
        "    11: 'Hepatic Vein',\n",
        "    12: 'Liver Ligament'\n",
        "}"
      ],
      "metadata": {
        "id": "EhstpK8e2X9y"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Dataset Pipeline \"\"\"\n",
        "\n",
        "train_dataset = tf_dataset(train_x,train_y,batch = batch_size)\n",
        "valid_dataset = tf_dataset(val_x,val_y,batch=batch_size)\n"
      ],
      "metadata": {
        "id": "BPATrkKiMj49"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Model \"\"\"\n",
        "model = build_unet(input_shape,NUM_CLASSES)\n",
        "model.compile(\n",
        "    loss = \"categorical_crossentropy\",\n",
        "    optimizer = Adam(lr),\n",
        ")"
      ],
      "metadata": {
        "id": "BthLfbCRN3Vg"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Training \"\"\"\n",
        "\n",
        "callbacks = [\n",
        "    ModelCheckpoint(model_path,verbose=1,save_best_only=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n",
        "    CSVLogger(csv_path,append=True),\n",
        "    EarlyStopping(monitor='val_loss',patience=20,restore_best_weights=False)\n",
        "]"
      ],
      "metadata": {
        "id": "mipuJ8tDOTBO"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJjMx9G6QMdG",
        "outputId": "47766830-109d-4e6f-9cfa-3cd39067dda9"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2424"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_dataset,validation_data=valid_dataset,epochs=epochs,callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 587
        },
        "id": "gVDInIF1QEJn",
        "outputId": "7ca75136-4b51-4b1c-e32a-7954f0e5dbb4"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"U-Net\" is incompatible with the layer: expected shape=(None, 320, 416, 3), found shape=(320, 416, 3)\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-11a91ae5b45d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"U-Net\" is incompatible with the layer: expected shape=(None, 320, 416, 3), found shape=(320, 416, 3)\n"
          ]
        }
      ]
    }
  ]
}